// Note: all terms referring to size are in bytes, unless suffixed with _mb, _tb, etc.
// Note: all terms referring to time are in seconds, unless suffixed with _mins, _days, etc.

Rig:
  rig_storage_min = rig_storage_min_tb * 1024 * 1024 * 1024 * 1024
  rig_sectors_min = rig_storage_min / sector_size
  rig_storage_parallelization_min = post_disk_latency / polling_time
  rig_storage_unit_min = rig_storage_min / rig_storage_parallelization_min
  rig_storage_unit_min_tb = rig_storage_unit_min / (1024 * 1024 * 1024 * 1024)

Utils:
  b_in_gb = (1024 * 1024 * 1024)
  secs_in_month = (24 * 30 * 60 * 60)
  cid_size = 32 + 1 + 1 + 1

ProofOfSpacetime:
  post_vanilla_size = node_size * (log2(nodes) + 1) * post_challenges

  Time:
    post_disk_latency = post_challenges * challenged_sectors_percentage * rig_sectors_min * rig_storage_latency
    post_time = post_disk_latency + post_proof_gen

  Time (NoWrapper):
    //rig_storage_latency_throughput_kb = rig_storage_latency_throughput / 1024
    //response_honest_min = (post_challenges * challenged_sectors_percentage * rig_sectors_min * rig_storage_latency * windows) / rig_storage_latency_throughput

  SNARK:
    inclusion_proof = merkle_tree_hash_constraints * log2(nodes)
    inclusion_proofs = inclusion_proof * post_challenges
    ticket_proofs = ticket_constraints * post_challenges
    post_snark_constraints = ticket_proofs + inclusion_proofs

    post_snark_partitions = post_snark_constraints / post_max_snark_constraints
    post_snark_size = post_snark_partitions * snark_size
    post_snark_size_kb = post_snark_size / 1024

ProofOfReplication:
  Security:
    porep_challenges = -lambda / (log2(1-spacegap/4))

  Graph:
    sector_size = sector_size_gb * b_in_gb
    graph_parents = drg_parents + expander_parents
    nodes = sector_size / node_size 
    node_size_gb = node_size / b_in_gb 
    node_hash_size_gb = graph_parents * node_size_gb
    node_hash_size = node_hash_size_gb * b_in_gb

    window_size = window_size_mb * 1024 * 1024
    windows = sector_size / window_size
    window_nodes = nodes / windows

  Time:
    porep_time = porep_proof_gen + porep_commit_time + encoding_time
    porep_time_parallel = porel_proof_gen_parallel + porep_commit_time_parallel + encoding_time_parallel

  Commitment:
    commit_size = cid_size
    window_comm_tree_time = merkle_tree_hash_time * window_nodes
    window_comm_leaves_time = leaf_hash_time * windows
    commr_size = commit_size
    commd_size = commit_size
    commrlast_size = commit_size

    seal_commitment_size = commd_size + commr_size
    // seal_commitment_time = commr_time

    commd_time = merkle_tree_datahash_time * nodes

    // TODO commr might be twice depending on CommQ
    porep_commit_time = commr_time + commc_time
    porep_commit_time_mins = porep_commit_time / 60

    CommR (VectorR):
      commr_time = merkle_tree_hash_time * nodes

    CommR (ColumnR):
      commr_time = window_comm_tree_time + window_comm_leaves_time 

    CommC:
      commc_tree_time = (window_comm_tree_time + window_comm_leaves_time) * drg_layers 

  Encoding:
    encoding_window_time = (window_nodes * graph_parents) * kdf_time * drg_layers
    encoding_time = encoding_window_time * windows
    decoding_time = encoding_window_time

    encoding_time_parallel = encoding_time / rig_cores
    window_time_parallel = encoding_window_time / rig_cores

    Asic:
      encoding_time_parallel_asic = encoding_time_parallel / hashing_amax
      encoding_time_asic = encoding_time / hashing_amax
      encoding_window_time_asic = encoding_window_time / hashing_amax
      encoding_window_time_parallel_asic = encoding_window_time_parallel / hashing_amax

  Retrieval:
    // window_read = rig_storage_read_mbs * window_size_mb

  SNARK:
    // D
    // Data layer committed with merkle tree
    data_inclusion = merkle_tree_datahash_constraints * log2(nodes)
    data_inclusions = data_inclusion * porep_challenges
    window_data_inclusions = data_inclusion * porep_challenges * windows

    // C
    window_inclusion = merkle_tree_hash_constraints * log2(window_nodes)
    window_inclusions =  window_inclusion * porep_challenges * (graph_parents + 1)
    column_leaf = leaf_hash_constraints * drg_layers
    column_leaves = column_leaf * porep_challenges * (graph_parents + 1)
    window_column_leaves = column_leaves * windows
    labeling_proof = kdf_constraints * graph_parents
    labeling_proofs = labeling_proof * drg_layers * porep_challenges
    window_labeling_proof = labeling_proofs * windows

    // Q and R
    replica_inclusion = merkle_tree_hash_constraints * log2(nodes)
    replica_inclusions = replica_inclusion * porep_challenges
    window_replica_inclusions = replica_inclusions * windows

    porep_snark_partitions = porep_snark_constraints / porep_max_snark_constraints
    porep_snark_size = porep_snark_partitions * snark_size
    porep_snark_size_kb = porep_snark_size / 1024

    Constraints (WindowEncoding):
      porep_snark_constraints = window_inclusions + window_column_leaves + window_labeling_proof + window_data_inclusions + window_replica_inclusions*2

    Constraints (SectorEncoding):
      porep_snark_constraints = window_inclusions + window_column_leaves + window_labeling_proof + data_inclusions + replica_inclusions*2

    Constraints (Wrapping):
      porep_snark_constraints = window_inclusions + window_column_leaves + window_labeling_proof + data_inclusions + replica_inclusions*2

    // Column comitting data or replica. 

Rationality:
  describe(breakeven_nodes, "number of nodes / sector / challenge period after which it's cheaper to pay store the entire sector, than re-encode those")
  breakeven_nodes = ((cost_gb_per_month *  sector_size_gb) / (cost_hash_node * challenge_periods_per_month))
  challenge_periods_per_month = secs_in_month / polling_time
  regeneration_percentage = breakeven_nodes / nodes

  Costs:
    Compute:
      nodes_per_second = hash_gb_per_second / node_hash_size_gb
      nodes_per_year = nodes_per_second * (60 * 60 * 24 * 365)
      cost_hash_node = rig_cost_per_year / nodes_per_year 

    Storage:
      cost_storage_gbs = cost_gb_per_month / secs_in_month 
      cost_storage_sector_polling_time = cost_storage_gbs * (sector_size_gb * (polling_time + extra_storage_time))

// Throughput:
//   num_parallel_encoding = rig_ram_gb * rig_size / sector_size_gb
//   rig_cores = num_parallel_encoding
//   seal_throughput = (sector_size_gb * num_parallel_encoding) / encoding_time